{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.addPyFile(\"/opt/homebrew/Cellar/apache-spark/3.1.2/libexec/jars/graphframes-0.8.0-spark3.0-s_2.12.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphframes import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Vertics DataFrame\n",
    "v = spark.createDataFrame([\n",
    "  (\"a\", \"Alice\", 34),\n",
    "  (\"b\", \"Bob\", 36),\n",
    "  (\"c\", \"Charlie\", 37),\n",
    "  (\"d\", \"David\", 29),\n",
    "  (\"e\", \"Esther\", 32),\n",
    "  (\"f\", \"Fanny\", 38),\n",
    "  (\"g\", \"Gabby\", 60)\n",
    "], [\"id\", \"name\", \"age\"])\n",
    "\n",
    "# Edges DataFrame\n",
    "e = spark.createDataFrame([\n",
    "  (\"a\", \"b\", \"friend\"),\n",
    "  (\"b\", \"c\", \"follow\"),\n",
    "  (\"c\", \"b\", \"follow\"),\n",
    "  (\"f\", \"c\", \"follow\"),\n",
    "  (\"e\", \"f\", \"follow\"),\n",
    "  (\"e\", \"d\", \"friend\"),\n",
    "  (\"d\", \"a\", \"friend\"),\n",
    "  (\"a\", \"e\", \"friend\"),\n",
    "  (\"g\", \"e\", \"follow\")\n",
    "], [\"src\", \"dst\", \"relationship\"])\n",
    "\n",
    "# Create a GraphFrame\n",
    "g = GraphFrame(v, e)\n",
    "\n",
    "g.vertices.show()\n",
    "g.edges.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g.vertices and g.edges are just DataFrames\n",
    "# You can use any DataFrame API on them\n",
    "\n",
    "g.edges.filter(\"src = 'a'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.edges.filter(\"src = 'a'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of followers of c.\n",
    "# This queries the edge DataFrame.\n",
    "print(g.edges.filter(\"relationship = 'follow' and dst = 'c'\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A GraphFrame has additional attributes\n",
    "\n",
    "g.outDegrees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.inDegrees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.inDegrees.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myInDegrees = g.edges.groupBy('dst').count()\\\n",
    "               .withColumnRenamed('dst', 'id').withColumnRenamed('count', 'inDegree')\n",
    "myInDegrees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myInDegrees.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g.inDegrees.storageLevel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.inDegrees.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g.inDegrees.storageLevel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g.vertices.storageLevel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g.vertices.storageLevel)\n",
    "print(g.edges.storageLevel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A triplet view of the graph\n",
    "\n",
    "g.triplets.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.triplets.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motif Finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for pairs of vertices with edges in both directions between them.\n",
    "motifs = g.find(\"(a)-[]->(b); (b)-[]->(a)\").filter('a.id < b.id')\n",
    "motifs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find triangles\n",
    "\n",
    "triangles = g.find(\"(a)-[]->(b); (b)-[]->(c); (c)-[]->(a)\")\n",
    "triangles = triangles.filter(\"a.id < b.id AND a.id < c.id\")\n",
    "triangles.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangles.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negation\n",
    "oneway = g.find(\"(a)-[]->(b); !(b)-[]->(a)\")\n",
    "oneway.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find vertices without incoming edges:\n",
    "g.find(\"!()-[]->(a)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More meaningful queries can be expressed by applying filters.\n",
    "# Question: where is this filter applied?\n",
    "\n",
    "g.find(\"(a)-[e]->(b); (b)-[]->(a)\").filter(\"b.age > 36\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.find(\"(a)-[]->(b); (b)-[]->(a)\").filter(\"b.age > 36\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find chains of 4 vertices such that at least 2 of the 3 edges are \"friend\" relationships.\n",
    "# The when function is similar to the CASE WHEN in SQL\n",
    "\n",
    "chain4 = g.find(\"(a)-[e1]->(b); (b)-[e2]->(c); (c)-[e3]->(d)\").where('a!=d AND a!=c AND b!=d')\n",
    "\n",
    "friendTo1 = lambda e: when(e['relationship'] == 'friend', 1).otherwise(0)\n",
    "\n",
    "chain4.select('*',friendTo1(chain4['e1']).alias('f1'), \\\n",
    "                  friendTo1(chain4['e2']).alias('f2'), \\\n",
    "                  friendTo1(chain4['e3']).alias('f3')) \\\n",
    "      .where('f1 + f2 + f3 >= 2').select('a', 'b', 'c', 'd').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select subgraph of users older than 30, and relationships of type \"friend\".\n",
    "# Drop isolated vertices (users) which are not contained in any edges (relationships).\n",
    "\n",
    "g1 = g.filterVertices(\"age > 30\").filterEdges(\"relationship = 'friend'\")\\\n",
    "      .dropIsolatedVertices()\n",
    "\n",
    "g1.vertices.show()\n",
    "g1.edges.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select subgraph based on edges \"e\" of type \"follow\"\n",
    "# pointing from a younger user \"a\" to an older user \"b\".\n",
    "\n",
    "paths = g.find(\"(a)-[e]->(b)\")\\\n",
    "  .filter(\"e.relationship = 'follow'\")\\\n",
    "  .filter(\"a.age < b.age\")\n",
    "\n",
    "paths.show()\n",
    "# \"paths\" contains vertex info. Extract the edges.\n",
    "\n",
    "e2 = paths.select(\"e.*\")\n",
    "e2.show()\n",
    "\n",
    "# Construct the subgraph\n",
    "g2 = GraphFrame(g.vertices, e2).dropIsolatedVertices()\n",
    "\n",
    "g2.vertices.show()\n",
    "g2.edges.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting vertex is 'a'\n",
    "layers = [g.vertices.select('id').where(\"id = 'a'\")]\n",
    "visited =  layers[0]\n",
    "\n",
    "while layers[-1].count() > 0:\n",
    "    # From the current layer, get all the one-hop neighbors\n",
    "    d1 = layers[-1].join(g.edges, layers[-1]['id'] == g.edges['src'])\n",
    "    # Rename the column as 'id', and remove visited verices and duplicates\n",
    "    d2 = d1.select(d1['dst'].alias('id')) \\\n",
    "           .subtract(visited).distinct().cache()\n",
    "    layers += [d2]\n",
    "    visited = visited.union(layers[-1]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers[1].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers[2].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers[3].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+---------------+--------------+----------------+\n",
      "|          from|            e0|             v1|            e1|              to|\n",
      "+--------------+--------------+---------------+--------------+----------------+\n",
      "|{a, Alice, 34}|{a, e, friend}|{e, Esther, 32}|{e, f, follow}|  {f, Fanny, 38}|\n",
      "|{a, Alice, 34}|{a, b, friend}|   {b, Bob, 36}|{b, c, follow}|{c, Charlie, 37}|\n",
      "+--------------+--------------+---------------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GraphFrames provides own BFS:\n",
    "\n",
    "paths = g.bfs(\"id = 'a'\", \"age > 36\")\n",
    "paths.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1 denotes end of list\n",
    "data = [(0, 5), (1, 0), (3, 4), (4, 6), (5, -1), (6,1)]\n",
    "e = spark.createDataFrame(data, ['src', 'dst'])\n",
    "v = e.select(col('src').alias('id'), when(e.dst == -1, 0).otherwise(1).alias('d'))\n",
    "v1 = spark.createDataFrame([(-1, 0)], ['id', 'd'])\n",
    "v = v.union(v1)\n",
    "v.show()\n",
    "e.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while e.filter('dst != -1').count() > 0:\n",
    "    g = GraphFrame(v, e)\n",
    "    g.cache()\n",
    "    v = g.triplets.select(col('src.id').alias('id'), \n",
    "                          (col('src.d') + col('dst.d')).alias('d')) \\\n",
    "         .union(v1)\n",
    "    e = g.find('(a)-[]->(b); (b)-[]->(c)') \\\n",
    "         .select(col('a.id').alias('src'), col('c.id').alias('dst')) \\\n",
    "         .union(e.filter('dst = -1'))\n",
    "    e.show()\n",
    "v.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message passing via AggregateMessages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import coalesce, col, lit, sum, when, min, max\n",
    "from graphframes.lib import AggregateMessages as AM\n",
    "\n",
    "# AggregateMessages has the following members: src, dst, edge, msg\n",
    "# For each user, sum the ages of the adjacent users.\n",
    "agg = g.aggregateMessages(\n",
    "    sum(AM.msg).alias(\"summedAges\"),\n",
    "    #sendToSrc = AM.dst['age'],\n",
    "    sendToDst = AM.src['age'])\n",
    "agg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The Pregel Model for Graph Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pagerank in the Pregel model \n",
    "\n",
    "from pyspark.sql.functions import coalesce, col, lit, sum, when, min\n",
    "from graphframes.lib import Pregel\n",
    "\n",
    "# Need to set up a directory for Pregel computation\n",
    "sc.setCheckpointDir(\"checkpoint\")\n",
    "\n",
    "'''\n",
    "Use builder pattern to describe the operations.\n",
    "Call run() to start a run. It returns a DataFrame of vertices from the last iteration.\n",
    "\n",
    "When a run starts, it expands the vertices DataFrame using column expressions \n",
    "defined by withVertexColumn(). Those additional vertex properties can be \n",
    "changed during Pregel iterations. In each Pregel iteration, there are three \n",
    "phases:\n",
    "\n",
    "* Given each edge triplet, generate messages and specify target vertices to \n",
    "  send, described by sendMsgToDst() and sendMsgToSrc().\n",
    "* Aggregate messages by target vertex IDs, described by aggMsgs().\n",
    "* Update additional vertex properties based on aggregated messages and states \n",
    "  from previous iteration, described by withVertexColumn().\n",
    "'''\n",
    "v = g.outDegrees\n",
    "g = GraphFrame(v,e)\n",
    "ranks = g.pregel \\\n",
    "        .setMaxIter(5) \\\n",
    "        .sendMsgToDst(Pregel.src(\"rank\") / Pregel.src(\"outDegree\")) \\\n",
    "        .aggMsgs(sum(Pregel.msg())) \\\n",
    "        .withVertexColumn(\"rank\", lit(1.0), \\\n",
    "            coalesce(Pregel.msg(), lit(0.0)) * lit(0.85) + lit(0.15)) \\\n",
    "        .run()\n",
    "ranks.show()\n",
    "\n",
    "# pyspark.sql.functions.coalesce(*cols): Returns the first column that is not null.\n",
    "# Not to be confused with spark.sql.coalesce(numPartitions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BFS in the Pregel model\n",
    "\n",
    "g = GraphFrame(v,e)\n",
    "\n",
    "dist = g.pregel \\\n",
    "        .sendMsgToDst(when(Pregel.src('active'), Pregel.src('d') + 1)) \\\n",
    "        .aggMsgs(min(Pregel.msg())) \\\n",
    "        .withVertexColumn('d', when(v['id'] == 'a', 0).otherwise(99999), \\\n",
    "            when(Pregel.msg() < col('d'), Pregel.msg()).otherwise(col('d'))) \\\n",
    "        .withVertexColumn('active', when(v['id'] == 'a', True).otherwise(False), \\\n",
    "            when(Pregel.msg() < col('d'), True).otherwise(False)) \\\n",
    "        .run()\n",
    "dist.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
