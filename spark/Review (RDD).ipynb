{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae38251c",
   "metadata": {},
   "source": [
    "# RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d298393",
   "metadata": {},
   "source": [
    "## Read and Play "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa71292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from local\n",
    "fruits = sc.textFile('../data/fruits.txt')\n",
    "yellowThings = sc.textFile('../data/yellowthings.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887c8263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from HDFS\n",
    "HDFS = sc.textFile('hdfs://url:9000/fruits.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cdfb3b",
   "metadata": {},
   "source": [
    "RDD actions:\n",
    "1. rdd.collect() list of all items\n",
    "2. rdd.count() long type, number of items in this rdd\n",
    "3. rdd.first() first item\n",
    "4. rdd.reduce()\n",
    "5. rdd.lookup()\n",
    "6. rdd.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fd9de7",
   "metadata": {},
   "source": [
    "RDD Transformations:\n",
    "1. rdd.map() Returns a stream consisting of the results of applying the given function to the elements of this stream.\n",
    "2. rdd.filter()\n",
    "3. rdd.flatMap() Returns a stream consisting of the results of replacing each element of this stream with the contents of a mapped stream produced by applying the provided mapping function to each element.\n",
    "4. rdd.sample()\n",
    "5. rdd.groupByKey()\n",
    "6. rdd.reduceByKey()\n",
    "7. union()\n",
    "8. join()\n",
    "9. cogroup()\n",
    "10. corssProduct()\n",
    "11. rdd.mapValues()\n",
    "12. rdd.sort()\n",
    "13. rdd.partitionBy()\n",
    "14. rdd.glom()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5565b353",
   "metadata": {},
   "source": [
    "## Transformation with Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bd224aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# union \n",
    "fruitsAndYellowThings = fruits.union(yellowThings)\n",
    "# intersection\n",
    "yellowFruits = fruits.intersection(yellowThings)\n",
    "# distinct\n",
    "distinctFruitsAndYellowThings = fruitsAndYellowThings.distinct()\n",
    "# check\n",
    "fruitsAndYellowThings.count() == yellowFruits.count() + distinctFruitsAndYellowThings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a994f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'grap', 'lemon']\n",
      "['apple', 'banana', 'canary melon', 'grap', 'orange', 'pineapple', 'strawberry']\n"
     ]
    }
   ],
   "source": [
    "# filter\n",
    "k = 5\n",
    "shortFruits = fruits.filter(lambda fruit: len(fruit) <= k)\n",
    "print(shortFruits.collect())\n",
    "fruits_with_a = fruits.filter(lambda fruit: 'a' in fruit)\n",
    "print(fruits_with_a.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acd22655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elppa', 'ananab', 'nolem yranac', 'parg', 'nomel', 'egnaro', 'elppaenip', 'yrrebwarts']\n"
     ]
    }
   ],
   "source": [
    "# map 把二箱鸡蛋分别加工成煎蛋，还是放成原来的两箱，分给2组学生\n",
    "# [::-1] 翻转读取\n",
    "fruitsReversed = fruits.map(lambda fruit: fruit[::-1])\n",
    "print(fruitsReversed.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "325403d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'p', 'p', 'l', 'e', 'b', 'a', 'n', 'a', 'n', 'a', 'c', 'a', 'n', 'a', 'r', 'y', ' ', 'm', 'e', 'l', 'o', 'n', 'g', 'r', 'a', 'p', 'l', 'e', 'm', 'o', 'n', 'o', 'r', 'a', 'n', 'g', 'e', 'p', 'i', 'n', 'e', 'a', 'p', 'p', 'l', 'e', 's', 't', 'r', 'a', 'w', 'b', 'e', 'r', 'r', 'y']\n"
     ]
    }
   ],
   "source": [
    "# flatMap 把二箱鸡蛋分别加工成煎蛋，然后放到一起（100个煎蛋），分给100个学生\n",
    "characters = fruits.flatMap(lambda fruit: list(fruit))\n",
    "print(characters.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8467d52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glom give list of elements by each partition\n",
    "import sys\n",
    "import random\n",
    "\n",
    "def f(_):\n",
    "    return random.random()\n",
    "\n",
    "a = sc.parallelize(range(0,100),10)\n",
    "#print(a.collect())\n",
    "#print(a.glom().collect())\n",
    "#print(a.map(f).glom().collect())\n",
    "\n",
    "# Weird behavior: Initially, random numbers are synched across all workers, but will get \n",
    "# out-of-sync after a large (e.g, 1000000) number of random numbers have been generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9e6a4e36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19]]\n",
      "[0, 6, 10, 18, 26, 10, 46, 60, 48, 66]\n",
      "[0, 1, 3, 6, 10, 5, 11, 18, 26, 35, 10, 21, 33, 46, 60, 15, 31, 48, 66, 85]\n",
      "[0, 1, 3, 6, 10, 6, 12, 19, 27, 36, 12, 23, 35, 48, 62, 18, 34, 51, 69, 88]\n"
     ]
    }
   ],
   "source": [
    "# mapPartition and mapPartitionWithIndex\n",
    "a = sc.parallelize(range(0,20),4)\n",
    "print(a.glom().collect())\n",
    "\n",
    "def f(it):\n",
    "    s = 0\n",
    "    l = []\n",
    "    for i in it:\n",
    "        s += i\n",
    "        if s % 2 == 0:\n",
    "            l.append(s)\n",
    "    return l\n",
    "\n",
    "print(a.mapPartitions(f).collect())\n",
    "\n",
    "def f(it):\n",
    "    s = 0\n",
    "    for i in it:\n",
    "        s += i\n",
    "        yield s             #everything in yielded loop will \\\n",
    "                            #constricted into a output list\n",
    "                            #the list not physically exist.\n",
    "                            #recomand this one.\n",
    "        \n",
    "\n",
    "print(a.mapPartitions(f).collect())\n",
    "\n",
    "def f(index, it):\n",
    "    s = index\n",
    "    for i in it:\n",
    "        s += i\n",
    "        yield s\n",
    "\n",
    "print(a.mapPartitionsWithIndex(f).collect()) # it allows f have 2 parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066a29fd",
   "metadata": {},
   "source": [
    "## Actions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3411e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect\n",
    "fruitsArray = fruits.collect()\n",
    "yellowThingsArray = yellowThings.collect()\n",
    "# count\n",
    "numFruits = fruits.count()\n",
    "# take\n",
    "first3Fruits = fruits.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6c182e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'o', 'r', 'a', 'i', 'p', 'g', 'c', ' ', 'l', 'y', 'e', 'w', 'n', 'b', 'm', 't', 's'}\n"
     ]
    }
   ],
   "source": [
    "# map reduce\n",
    "letterSet = fruits.map(lambda fruit: set(fruit)).collect()\n",
    "#print(letterSet)\n",
    "letterSet = fruits.map(lambda fruit: set(fruit)).reduce(lambda x, y: x.union(y))\n",
    "print(letterSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad5d51cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p', 'l', 'b', 'c', 'r', 'y', 'g', 'i', 's', 'a', 'e', 'n', ' ', 'm', 'o', 't', 'w']\n"
     ]
    }
   ],
   "source": [
    "letterSet = fruits.flatMap(lambda fruit: list(fruit)).collect()\n",
    "#print(letterSet)\n",
    "letterSet = fruits.flatMap(lambda fruit: list(fruit)).distinct().collect()\n",
    "print(letterSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "67f75956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, 2), (12, 1), (4, 1), (10, 1), (5, 2), (9, 1)]\n"
     ]
    }
   ],
   "source": [
    "# reduceByKey\n",
    "numFruitsByLength = fruits.map(lambda fruit: (len(fruit), 1)).reduceByKey(lambda x, y: x + y)\n",
    "print(numFruitsByLength.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "00cfbb54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Big', 1), ('Course', 2), ('Description', 1), ('Information', 1), ('Lecture', 1), ('This', 1), ('across', 1), ('amount', 1), ('and', 3), ('as', 1), ('both', 1), ('centers.', 1), ('cloud', 1), ('commodity', 1), ('computing', 1), ('course', 1), ('data', 4), ('emerge', 1), ('enabling', 1), ('even', 1)]\n"
     ]
    }
   ],
   "source": [
    "from operator import add\n",
    "\n",
    "lines = sc.textFile('../data/course.txt')\n",
    "#print(lines.take(1))\n",
    "counts = lines.flatMap(lambda x: x.split()) \\\n",
    "              .map(lambda x: (x, 1)) \\\n",
    "              .reduceByKey(add)\n",
    "print(counts.sortByKey().take(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "adfad123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('data', 4), ('of', 3), ('and', 3), ('Course', 2), ('in', 2), ('the', 2), ('Information', 1), ('systems,', 1), ('cloud', 1), ('parallel', 1), ('as', 1), ('mining', 1), ('massive', 1), ('amount', 1), ('even', 1), ('servers', 1), ('centers.', 1), ('both', 1), ('hands-on', 1), ('this', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(counts.sortBy(lambda x: x[1], False).take(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "eb1b08e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, ('Apple', (134, 'OK'))), (1, ('Apple', (135, 'OK'))), (1, ('Apple', (45, 'OK'))), (2, ('Orange', (53, 'OK'))), (3, ('TV', (34, 'OK'))), (5, ('Computer', (162, 'Error')))]\n"
     ]
    }
   ],
   "source": [
    "# Join simple example\n",
    "\n",
    "products = sc.parallelize([(1, \"Apple\"), (2, \"Orange\"), (3, \"TV\"), (5, \"Computer\")])\n",
    "#trans = sc.parallelize([(1, 134, \"OK\"), (3, 34, \"OK\"), (5, 162, \"Error\"), (1, 135, \"OK\"), (2, 53, \"OK\"), (1, 45, \"OK\")])\n",
    "trans = sc.parallelize([(1, (134, \"OK\")), (3, (34, \"OK\")), (5, (162, \"Error\")), (1, (135, \"OK\")), (2, (53, \"OK\")), (1, (45, \"OK\"))])\n",
    "\n",
    "print(products.join(trans).take(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c6695f",
   "metadata": {},
   "source": [
    "## Join vs. Broadcast Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6db4b82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, ((134, 'OK'), 'Apple')), (1, ((135, 'OK'), 'Apple')), (1, ((45, 'OK'), 'Apple')), (2, ((53, 'OK'), 'Orange')), (3, ((34, 'OK'), 'TV')), (5, ((162, 'Error'), 'Computer'))]\n"
     ]
    }
   ],
   "source": [
    "products = sc.parallelize([(1, \"Apple\"), (2, \"Orange\"), (3, \"TV\"), (5, \"Computer\")])\n",
    "trans = sc.parallelize([(1, (134, \"OK\")), (3, (34, \"OK\")), (5, (162, \"Error\")), (1, (135, \"OK\")), (2, (53, \"OK\")), (1, (45, \"OK\"))])\n",
    "\n",
    "print(trans.join(products).take(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "99c035a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Apple', (134, 'OK')), (3, 'TV', (34, 'OK')), (5, 'Computer', (162, 'Error')), (1, 'Apple', (135, 'OK')), (2, 'Orange', (53, 'OK')), (1, 'Apple', (45, 'OK'))]\n",
      "[(1, 'Apple', (134, 'OK')), (3, 'TV', (34, 'OK')), (5, 'Computer', (162, 'Error')), (1, 'Apple', (135, 'OK')), (2, 'Orange', (53, 'OK')), (1, 'Apple', (45, 'OK'))]\n"
     ]
    }
   ],
   "source": [
    "products = {1: \"Apple\", 2: \"Orange\", 3: \"TV\", 5: \"Computer\"}\n",
    "trans = sc.parallelize([(1, (134, \"OK\")), (3, (34, \"OK\")), (5, (162, \"Error\")), (1, (135, \"OK\")), (2, (53, \"OK\")), (1, (45, \"OK\"))])\n",
    "\n",
    "broadcasted_products = sc.broadcast(products)\n",
    "\n",
    "results = trans.map(lambda x: (x[0], broadcasted_products.value[x[0]], x[1]))\n",
    "print(results.take(20))\n",
    "results = trans.map(lambda x: (x[0], products[x[0]], x[1]))\n",
    "print(results.take(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b51713",
   "metadata": {},
   "source": [
    "## Closure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea9b21f",
   "metadata": {},
   "source": [
    "A task’s closure is those variables and methods which must be visible for the executor to perform its computations on the RDD. (functions, global variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "718d9d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "0\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "rdd = sc.parallelize(range(10))\n",
    "\n",
    "# Wrong: Don't do this!!\n",
    "def increment_counter(x):\n",
    "    global counter\n",
    "    counter += x\n",
    "\n",
    "print(rdd.collect())\n",
    "rdd.foreach(increment_counter)\n",
    "\n",
    "print(counter)\n",
    "print(rdd.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd8a867a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(10))\n",
    "accum = sc.accumulator(0)\n",
    "\n",
    "def g(x):\n",
    "    global accum\n",
    "    accum += x\n",
    "\n",
    "a = rdd.foreach(g)\n",
    "print(accum.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41ac79d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "285\n",
      "90\n",
      "45\n",
      "90\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(10))\n",
    "accum = sc.accumulator(0)\n",
    "\n",
    "def g(x):\n",
    "    global accum\n",
    "    accum += x\n",
    "    return x * x\n",
    "\n",
    "a = rdd.map(g)\n",
    "print(accum.value)\n",
    "print(a.reduce(lambda x, y: x+y)) # 0+1+4+9+16+25+36+49+64+81, accum=45\n",
    "a.cache()\n",
    "tmp = a.count() # accum=45+45\n",
    "print(accum.value)\n",
    "print(rdd.reduce(lambda x, y: x+y))\n",
    "\n",
    "tmp = a.count()\n",
    "print(accum.value)\n",
    "print(rdd.reduce(lambda x, y: x+y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e46043",
   "metadata": {},
   "source": [
    "# PMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6ef7075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "lines = sc.textFile('../data/adj_noun_pairs.txt', 8)\n",
    "# Converting lines into word pairs. \n",
    "# Data is dirty: some lines have more than 2 words, so filter them out.\n",
    "pairs = lines.map(lambda l: tuple(l.split())).filter(lambda p: len(p)==2)\n",
    "pairs.cache()\n",
    "N = pairs.count()\n",
    "# Compute the frequency of each pair.\n",
    "# Ignore pairs that not frequent enough.\n",
    "pair_freqs = pairs.map(lambda p: (p,1)).reduceByKey(lambda f1, f2: f1 + f2) \\\n",
    "                  .filter(lambda pf: pf[1] >= 100)\n",
    "# Computing the frequencies of the adjectives and the nouns.\n",
    "a_freqs = pairs.map(lambda p: (p[0],1)).reduceByKey(lambda x,y: x+y)\n",
    "n_freqs = pairs.map(lambda p: (p[1],1)).reduceByKey(lambda x,y: x+y)\n",
    "# Broadcasting the adjective and noun frequencies. \n",
    "n_dict = sc.broadcast(n_freqs.collectAsMap())   #python's map data structure.\n",
    "a_dict = sc.broadcast(a_freqs.collectAsMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f46befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "\n",
    "# Computing the PMI for a pair.\n",
    "def pmi_score(pair_freq):\n",
    "    w1, w2 = pair_freq[0]\n",
    "    f = pair_freq[1]\n",
    "    pmi = log(float(f)*N/(a_dict.value[w1]*n_dict.value[w2]), 2) #divided by N in nominator.\n",
    "    return pmi, (w1, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "752a3d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(14.41018838546462, ('magna', 'carta')),\n",
       " (13.071365888694997, ('polish-lithuanian', 'Commonwealth')),\n",
       " (12.990597616733414, ('nitrous', 'oxide')),\n",
       " (12.64972604311254, ('latter-day', 'Saints')),\n",
       " (12.50658937509916, ('stainless', 'steel')),\n",
       " (12.482331020687814, ('pave', 'runway')),\n",
       " (12.19140721768055, ('corporal', 'punishment')),\n",
       " (12.183248694293388, ('capital', 'punishment')),\n",
       " (12.147015483562537, ('rush', 'yard')),\n",
       " (12.109945794428935, ('globular', 'cluster'))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing the PMI for all pairs.\n",
    "scored_pairs = pair_freqs.map(pmi_score)\n",
    "# Printing the most strongly associated pairs. \n",
    "scored_pairs.top(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bd3c64",
   "metadata": {},
   "source": [
    "# PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b93b96e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1', 1.2981882732854677), ('4', 0.9999999999999998), ('3', 0.9999999999999998), ('2', 0.7018117267145316)]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from operator import add\n",
    "\n",
    "def computeContribs(urls, rank):\n",
    "    # Calculates URL contributions to the rank of other URLs.\n",
    "    num_urls = len(urls)\n",
    "    for url in urls:\n",
    "        yield (url, rank / num_urls)\n",
    "\n",
    "def parseNeighbors(urls):\n",
    "    # Parses a urls pair string into urls pair.\"\"\"\n",
    "    parts = urls.split(' ')\n",
    "    return parts[0], parts[1]\n",
    "\n",
    "# Loads in input file. It should be in format of:\n",
    "#     URL         neighbor URL\n",
    "#     URL         neighbor URL\n",
    "#     URL         neighbor URL\n",
    "#     ...\n",
    "\n",
    "# The data file can be downloaded at http://www.cse.ust.hk/msbd5003/data/*\n",
    "lines = sc.textFile(\"../data/pagerank_data.txt\", 2)\n",
    "# lines = sc.textFile(\"../data/dblp.in\", 5)\n",
    "\n",
    "numOfIterations = 10\n",
    "\n",
    "# Loads all URLs from input file and initialize their neighbors. \n",
    "links = lines.map(lambda urls: parseNeighbors(urls)) \\\n",
    "             .groupByKey()\n",
    "\n",
    "# Loads all URLs with other URL(s) link to from input file \n",
    "# and initialize ranks of them to one.\n",
    "ranks = links.mapValues(lambda neighbors: 1.0)\n",
    "# Calculates and updates URL ranks continuously using PageRank algorithm.\n",
    "for iteration in range(numOfIterations):\n",
    "    # Calculates URL contributions to the rank of other URLs.\n",
    "    contribs = links.join(ranks) \\\n",
    "                    .flatMap(lambda url_urls_rank:\n",
    "                             computeContribs(url_urls_rank[1][0],\n",
    "                                             url_urls_rank[1][1]))\n",
    "    # After the join, each element in the RDD is of the form\n",
    "    # (url, (list of neighbor urls, rank))\n",
    "    # Re-calculates URL ranks based on neighbor contributions.\n",
    "    ranks = contribs.reduceByKey(add).mapValues(lambda rank: rank * 0.85 + 0.15)\n",
    "    # ranks = contribs.reduceByKey(add).map(lambda t: (t[0], t[1] * 0.85 + 0.15))\n",
    "\n",
    "print(ranks.top(5, lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4142f4a5",
   "metadata": {},
   "source": [
    "# Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492c1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1\n",
    "from operator import add\n",
    "lines = sc.textFile('README.md')\n",
    "counts = lines.flatMap(lambda x: x.split()) \\\n",
    "              .map(lambda x: (x, 1)) \\\n",
    "              .reduceByKey(add)\n",
    "# Add one line to find the most frequent word.\n",
    "counts.max(lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560d4660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2\n",
    "#Modify the word count example above, \n",
    "#so that we only count the frequencies of those words consisting of 5 or more characters.\n",
    "counts = lines.flatMap(lambda x: x.split()) \\\n",
    "              .filter(lambda x: len(x)>=5) \\\n",
    "              .map(lambda x: (x, 1)) \\\n",
    "              .reduceByKey(add)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "de4ccc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Q3\n",
    "# What's its output? (Yes, you can just run it.)\n",
    "A = sc.parallelize(range(1, 100))\n",
    "t = 50\n",
    "B = A.filter(lambda x: x < t)\n",
    "print(B.count()) # 49\n",
    "t = 10\n",
    "C = B.filter(lambda x: x > t)\n",
    "print(C.count()) # 0 because C = A.filter(lambda x: x < t).filter(lambda x: x > t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "69c0a792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "# Q4\n",
    "#The intent of the code above is to get all numbers below 50 from A and put them into B, \n",
    "#and then get all numbers above 10 from B and put them into C.  \n",
    "#Fix the code so that it produces the desired behavior, by adding one line of code.  \n",
    "#You are not allowed to change the existing code.\n",
    "A = sc.parallelize(range(1, 100))\n",
    "t = 50\n",
    "B = A.filter(lambda x: x < t)\n",
    "print(B.count()) # 49\n",
    "B.cache()\n",
    "t = 10\n",
    "C = B.filter(lambda x: x > t)\n",
    "print(C.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64c9c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5\n",
    "#Modify the PMI example by sending a_dict and n_dict inside the closure. Do not use broadcast variables.\n",
    "import psutil\n",
    "lines = sc.textFile('../data/adj_noun_pairs.txt', 8)\n",
    "pairs = lines.map(lambda l: tuple(l.split())).filter(lambda p: len(p)==2)\n",
    "pairs.cache()\n",
    "N = pairs.count()\n",
    "a_freqs = pairs.map(lambda p: (p[0],1)).reduceByKey(lambda x,y: x+y)\n",
    "n_freqs = pairs.map(lambda p: (p[1],1)).reduceByKey(lambda x,y: x+y)\n",
    "pair_freqs = pairs.map(lambda p: (p,1)).reduceByKey(lambda f1, f2: f1 + f2) \\\n",
    "                  .filter(lambda pf: pf[1] >= 100)\n",
    "a_dict = a_freqs.collectAsMap()\n",
    "n_dict = n_freqs.collectAsMap()\n",
    "def pmi_score(pair_freq):\n",
    "    w1, w2 = pair_freq[0]\n",
    "    f = pair_freq[1]\n",
    "    pmi = log(float(f)*N/(a_dict[w1]*n_dict[w2]), 2) #divided by N in nominator.\n",
    "    return pmi, (w1, w2)\n",
    "scored_pairs = pair_freqs.map(pmi_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08c2097e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(14.41018838546462, ('magna', 'carta')),\n",
       " (13.071365888694997, ('polish-lithuanian', 'Commonwealth')),\n",
       " (12.990597616733414, ('nitrous', 'oxide')),\n",
       " (12.64972604311254, ('latter-day', 'Saints')),\n",
       " (12.50658937509916, ('stainless', 'steel')),\n",
       " (12.482331020687814, ('pave', 'runway')),\n",
       " (12.19140721768055, ('corporal', 'punishment')),\n",
       " (12.183248694293388, ('capital', 'punishment')),\n",
       " (12.147015483562537, ('rush', 'yard')),\n",
       " (12.109945794428935, ('globular', 'cluster'))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_pairs.top(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f90508f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102]\n"
     ]
    }
   ],
   "source": [
    "# Q6\n",
    "#The following code creates an RDD with 4 partitions: partition 0, 1, 2, and 3.\n",
    "A = sc.parallelize(range(100), 4)\n",
    "#For each item in the RDD, add its partition number to it, and write the results to another RDD, i.e., \n",
    "#the resulting RDD should contain:\n",
    "#[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, \n",
    "#21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, \n",
    "#41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, \n",
    "#61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, \n",
    "#81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102]\n",
    "def f(x, sets):\n",
    "    for i in sets:\n",
    "        yield x+i\n",
    "print(A.mapPartitionsWithIndex(f).collect())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
